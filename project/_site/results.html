<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>4. Results</title>

<script src="site_libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>

<link rel="stylesheet" href="styles.css" type="text/css" />



<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>


<style type="text/css">
/* padding for bootstrap navbar */
body {
  padding-top: 51px;
  padding-bottom: 40px;
}
/* offset scroll position for anchor links (for fixed navbar)  */
.section h1 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h2 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h3 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h4 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h5 {
  padding-top: 56px;
  margin-top: -56px;
}
.section h6 {
  padding-top: 56px;
  margin-top: -56px;
}
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #ffffff;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script>
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark it active
  menuAnchor.parent().addClass('active');

  // if it's got a parent navbar menu mark it active as well
  menuAnchor.closest('li.dropdown').addClass('active');
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Introduction to Neural Networks</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li class="dropdown">
  <a href="#" class="dropdown-toggle" data-toggle="dropdown" role="button" aria-expanded="false">
    Presentation
     
    <span class="caret"></span>
  </a>
  <ul class="dropdown-menu" role="menu">
    <li>
      <a href="architectures.html">Architectures</a>
    </li>
    <li>
      <a href="linear_algebra.html">Linear algebra</a>
    </li>
    <li>
      <a href="results.html">Results</a>
    </li>
    <li>
      <a href="comparison.html">Comparison</a>
    </li>
    <li>
      <a href="applicability.html">Applicability</a>
    </li>
    <li>
      <a href="references.html">References</a>
    </li>
  </ul>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div class="fluid-row" id="header">



<h1 class="title toc-ignore">4. Results</h1>

</div>


<p>
 
</p>
<p>One of the most popular high-level libraries for building machine learning models is <strong>Keras</strong>. In addition to Keras, we have also used ggplot2 for creating visualizations:</p>
<div id="data-loading-and-preparation" class="section level5">
<h5>Data loading and preparation</h5>
<p>As covered in the Problem section, the group used the MNIST Fashion dataset for training a model to classify clothing items:</p>
<p>We can also prepare a vector of the possible classes the model will attempt to classify samples as:</p>
<pre class="r"><code>classes = c(&#39;T-shirt/top&#39;,
            &#39;Trouser&#39;,
            &#39;Pullover&#39;,
            &#39;Dress&#39;,
            &#39;Coat&#39;,
            &#39;Sandal&#39;,
            &#39;Shirt&#39;,
            &#39;Sneaker&#39;,
            &#39;Bag&#39;,
            &#39;Ankle boot&#39;)</code></pre>
</div>
<div id="data-exploration" class="section level5">
<h5>Data exploration</h5>
<p>According to official documentation, there should be 60000 28 x 28 training images along with 60000 labels and 10000 28 x 28 test images along with 10000 test labels:</p>
<pre class="r"><code>dim(train_images)</code></pre>
<pre><code>## [1] 60000    28    28</code></pre>
<pre class="r"><code>dim(train_labels)</code></pre>
<pre><code>## [1] 60000</code></pre>
<pre class="r"><code>dim(test_images)</code></pre>
<pre><code>## [1] 10000    28    28</code></pre>
<pre class="r"><code>dim(test_labels)</code></pre>
<pre><code>## [1] 10000</code></pre>
<p>We can also plot a sample image of an item:</p>
<pre class="r"><code>sample_image &lt;- as.data.frame(train_images[666, , ])
colnames(sample_image) &lt;- seq_len(ncol(sample_image))
sample_image$y &lt;- seq_len(nrow(sample_image))
sample_image &lt;- gather(sample_image, &quot;x&quot;, &quot;value&quot;, -y)
sample_image$x &lt;- as.integer(sample_image$x)

p &lt;- ggplot(sample_image, aes(x=x, y=y, fill=value)) +
    geom_tile() +
    scale_fill_gradient(low=&quot;white&quot;, high=&quot;black&quot;, na.value=NA) +
    scale_y_reverse() +
    theme_minimal() +
    theme(panel.grid=element_blank()) +
    theme(aspect.ratio=1) +
    xlab(&quot;&quot;) +
    ylab(&quot;&quot;)
print(p)</code></pre>
<p><img src="results_files/figure-html/unnamed-chunk-5-1.png" width="960" /></p>
</div>
<div id="training" class="section level5">
<h5>Training</h5>
<p><strong>Neural networks</strong> deal more gracefully with values that are scaled to be between 0 and 1. The reason is large ranges, such as 0 to 255, can cause large perturbations in the output of the network because the values are large:</p>
<pre class="r"><code>train_images &lt;- train_images/255
test_images &lt;- test_images/255</code></pre>
<p>We can inspect a subset of the images to make sure they are in the expected format and have the correct labels based on visual inspection:</p>
<pre class="r"><code>par(mfcol=c(5,5))
par(mar=c(0, 0, 1.5, 0), xaxs=&#39;i&#39;, yaxs=&#39;i&#39;)
for(i in 42:66) {
    img &lt;- train_images[i, , ]
    img &lt;- t(apply(img, 2, rev))
    image(1:28, 1:28, img, col=gray((0:255)/255), xaxt=&#39;n&#39;, yaxt=&#39;n&#39;,
          main=paste(classes[train_labels[i] + 1]))
}</code></pre>
<p><img src="results_files/figure-html/unnamed-chunk-7-1.png" width="960" /></p>
<p>Now, we begin to build our model and establish our layers, which will start by shrinking the first layer into 32 values. After this layer has been evaluated by the sigmoid activation function, it will produce another level of 32 values, which goes through a different activation function (ReLU) before being sent to the final layer of ten values:</p>
<pre class="r"><code>model &lt;- keras_model_sequential()
model %&gt;%
    layer_flatten(input_shape=c(28, 28)) %&gt;%
    layer_dense(units=512, activation=&#39;sigmoid&#39;) %&gt;%
    layer_dropout(0.2) %&gt;%
    layer_dense(units=512, activation=&#39;relu&#39;)%&gt;%
    layer_dropout(0.2) %&gt;%
    layer_dense(units=10, activation=&#39;softmax&#39;)</code></pre>
<p>After establishing the layers, and during the compilation of the model, we must include some preliminary steps: <strong>the loss function, optimizer, and metrics</strong>. The <em>loss function</em> measure the difference between a given true label and the prediction of the network. The model uses the <em>optimizer</em> to update itself based on the data and loss function; adam specifically uses a <em>gradient-based optimization</em>. <em>Metrics</em> are what monitor the training and testing steps.</p>
<pre class="r"><code>model %&gt;% compile(optimizer=&#39;adam&#39;,
                  loss=&#39;sparse_categorical_crossentropy&#39;,
                  metrics=c(&#39;accuracy&#39;))</code></pre>
<p>With all of this set up, we are finally able to train our neural network. The “epochs” option determine how many cycles we let the network train upon. Here, we will train the network 10 times. At the end of each epoch, keras will update us on the loss and accuracy of each run as well as validation scores of our testing data set.</p>
<pre class="r"><code>history &lt;- model %&gt;% fit(train_images, train_labels,
                         epochs=25,
                         batch_size=128,
                         validation_data=list(test_images, test_labels),
                         view_metrics=FALSE)</code></pre>
</div>
<div id="prediction-results" class="section level5">
<h5>Prediction results</h5>
<p>After training the model, we can make some predictions with the set of test images (i.e., the model predicts the label for each image in correspondence to the 10 classes we had previously outlined). The highest value in the output distribution is what tells us what the model’s prediction is.</p>
<pre class="r"><code>prediction &lt;- model %&gt;% predict_classes(test_images)
prediction[1:20]</code></pre>
<pre><code>##  [1] 9 2 1 1 6 1 4 6 5 7 4 5 5 3 4 1 2 2 8 0</code></pre>
<pre class="r"><code>test_labels[1:20]</code></pre>
<pre><code>##  [1] 9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0</code></pre>
<p>For our last trick, we show the prediction results from a subset of the data visually. Correct predictions will show up with green text and wrong predictions will be shown with red text.</p>
<pre class="r"><code>par(mfcol=c(5,5))
par(mar=c(0, 0, 1.5, 0), xaxs=&#39;i&#39;, yaxs=&#39;i&#39;)
for (i in 1:25) {
  img &lt;- test_images[i, , ]
  img &lt;- t(apply(img, 2, rev))
  if (prediction[i] == test_labels[i]) {
    color &lt;- &#39;#34FE82&#39;
  } else {
    color &lt;- &#39;#FF5567&#39;
  }
  image(1:28, 1:28, img, col=gray((0:255)/255), xaxt=&#39;n&#39;, yaxt=&#39;n&#39;,
        main = paste0(classes[prediction[i] + 1], &quot; (&quot;,
                      classes[test_labels[i] + 1], &quot;)&quot;),
        col.main = color)
}</code></pre>
<p><img src="results_files/figure-html/unnamed-chunk-12-1.png" width="960" /></p>
</div>
<div id="sample-accuracy-and-loss-plots-from-the-training-process" class="section level5">
<h5>Sample accuracy and loss plots from the training process</h5>
<pre class="r"><code>train_acc &lt;- history$metrics$accuracy
train_loss &lt;- history$metrics$loss
val_acc &lt;- history$metrics$val_accuracy
val_loss &lt;- history$metrics$val_loss

acc &lt;- data.frame(train_acc=train_acc, val_acc=val_acc)
loss &lt;- data.frame(train_loss=train_loss, val_loss=val_loss)

ggplot(data=acc, aes(1:25, train_acc, color=&quot;blue&quot;)) + 
  geom_point() + 
  geom_point(data=acc, aes(1:25, val_acc, color=&quot;red&quot;)) +
  theme_bw() +
  labs(title=&quot;Training and validation accuracy during training&quot;, 
       x=&quot;Epoch&quot;, 
       y=&quot;Accuracy&quot;, 
       color=&quot;Dataset&quot;) +
  scale_color_manual(labels=c(&quot;Training&quot;, &quot;Validation&quot;), values=c(&quot;blue&quot;, &quot;red&quot;)) + 
  theme(plot.title=element_text(size=14, face=&quot;bold&quot;))</code></pre>
<p><img src="results_files/figure-html/unnamed-chunk-13-1.png" width="960" /></p>
<pre class="r"><code>ggplot(data=loss, aes(1:25, train_loss, color=&quot;blue&quot;)) + 
  geom_point() + 
  geom_point(data=loss, aes(1:25, val_loss, color=&quot;red&quot;)) +
  theme_bw() +
  labs(title=&quot;Training and validation loss during training&quot;, 
       x=&quot;Epoch&quot;, 
       y=&quot;Loss&quot;, 
       color=&quot;Dataset&quot;) +
  scale_color_manual(labels=c(&quot;Training&quot;, &quot;Validation&quot;), values=c(&quot;blue&quot;, &quot;red&quot;)) + 
  theme(plot.title=element_text(size=14, face=&quot;bold&quot;))</code></pre>
<p><img src="results_files/figure-html/unnamed-chunk-13-2.png" width="960" /></p>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
